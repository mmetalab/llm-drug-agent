{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ChemBERTa model and tokenizer for drug feature extraction\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Initialize the tokenizer and model for ChemBERTa\n",
    "chem_tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "chem_model = AutoModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESM2 model and tokenizer for protein feature extraction\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Initialize the tokenizer and model for ESM2\n",
    "esm_tokenizer = AutoTokenizer.from_pretrained(\"D:\\Drugllm\\esm2_t6_8M_UR50D\")\n",
    "esm_model = AutoModel.from_pretrained(\"D:\\Drugllm\\esm2_t6_8M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the hidden size of the ChemBERTa model\n",
    "print(chem_model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the hidden size of the ESM2 model\n",
    "print(esm_model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract features from drugs and proteins using pre-trained models\n",
    "def extract_chem_features(smiles):\n",
    "    \"\"\"Extract ChemBERTa features from SMILES strings.\"\"\"\n",
    "    try:\n",
    "        # Tokenize the SMILES string\n",
    "        tokens = chem_tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        # Generate embeddings using the ChemBERTa model\n",
    "        with torch.no_grad():\n",
    "            embeddings = chem_model(**tokens).last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        return embeddings\n",
    "    except:\n",
    "        # Return a zero vector if feature extraction fails\n",
    "        return np.zeros(768)\n",
    "\n",
    "def extract_esm_features(sequence):\n",
    "    \"\"\"Extract ESM2 features from protein sequences.\"\"\"\n",
    "    try:\n",
    "        # Tokenize the protein sequence\n",
    "        tokens = esm_tokenizer(sequence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        # Generate embeddings using the ESM2 model\n",
    "        with torch.no_grad():\n",
    "            embeddings = esm_model(**tokens).last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        return embeddings\n",
    "    except:\n",
    "        # Return a zero vector if feature extraction fails\n",
    "        return np.zeros(320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurize drugs\n",
    "# Extract unique drugs and proteins\n",
    "unique_drugs = bind_db[['Drug']].drop_duplicates()\n",
    "unique_proteins = bind_db[['Target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm for progress bars during feature extraction\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46605f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for unique drugs in the BindDB dataset\n",
    "tqdm.pandas()  # Enable progress bar for pandas operations\n",
    "unique_drugs['drug_features'] = unique_drugs['Drug'].progress_apply(extract_chem_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for unique proteins in the BindDB dataset\n",
    "unique_proteins['protein_features'] = unique_proteins['Target'].progress_apply(extract_esm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge extracted features back into the BindDB dataset\n",
    "bind_db = bind_db.merge(unique_drugs, on='Drug', how='left')\n",
    "bind_db = bind_db.merge(unique_proteins, on='Target', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the featurized BindDB dataset to a PyTorch file\n",
    "torch.save(bind_db, '/content/drive/MyDrive/DrugPLM-Cindy-2025/Code_and_Data/Data/BindDB/BindDB_featurized.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33350a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique drugs and proteins from the Davis dataset\n",
    "unique_drugs = davis_db[['Drug']].drop_duplicates()\n",
    "unique_proteins = davis_db[['Target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for unique drugs in the Davis dataset\n",
    "tqdm.pandas()  # Enable progress bar for pandas operations\n",
    "unique_drugs['drug_features'] = unique_drugs['Drug'].progress_apply(extract_chem_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for unique proteins in the Davis dataset\n",
    "unique_proteins['protein_features'] = unique_proteins['Target'].progress_apply(extract_esm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22619f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge extracted features back into the Davis dataset\n",
    "davis_db = davis_db.merge(unique_drugs, on='Drug', how='left')\n",
    "davis_db = davis_db.merge(unique_proteins, on='Target', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae801c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the featurized Davis dataset to a PyTorch file\n",
    "torch.save(davis_db, '/content/drive/MyDrive/DrugPLM-Cindy-2025/Code_and_Data/Data/Davis/Davis_featurized.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eade299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique drugs and proteins from the Kiba dataset\n",
    "unique_drugs = kiba_db[['Drug']].drop_duplicates()\n",
    "unique_proteins = kiba_db[['Target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbce833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for unique drugs in the Kiba dataset\n",
    "tqdm.pandas()  # Enable progress bar for pandas operations\n",
    "unique_drugs['drug_features'] = unique_drugs['Drug'].progress_apply(extract_chem_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for unique proteins in the Kiba dataset\n",
    "unique_proteins['protein_features'] = unique_proteins['Target'].progress_apply(extract_esm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee519ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge extracted features back into the Kiba dataset\n",
    "kiba_db = kiba_db.merge(unique_drugs, on='Drug', how='left')\n",
    "kiba_db = kiba_db.merge(unique_proteins, on='Target', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b4d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the featurized Kiba dataset to a PyTorch file\n",
    "torch.save(kiba_db, '/content/drive/MyDrive/DrugPLM-Cindy-2025/Code_and_Data/Data/Kiba/Kiba_featurized.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the featurized BindDB dataset for further analysis\n",
    "bind_db = torch.load('/content/drive/MyDrive/DrugPLM-Cindy-2025/Code_and_Data/Data/BindDB/BindDB_featurized.pt', weights_only=False)\n",
    "# Display the first few rows of the dataset\n",
    "bind_db.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
